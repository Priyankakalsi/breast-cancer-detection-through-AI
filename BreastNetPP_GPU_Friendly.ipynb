{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BreastNet++ - Efficient Breast Cancer Classifier (Optimized for GTX 1650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q efficientnet_pytorch albumentations timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\nuscenes_env\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CBAM Attention Module\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca = self.channel_attention(x)\n",
    "        x = x * ca\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        mean_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        sa_input = torch.cat([max_out, mean_out], dim=1)\n",
    "        sa = self.spatial_attention(sa_input)\n",
    "        x = x * sa\n",
    "        return x\n",
    "\n",
    "# EfficientNet-B0 + CBAM model\n",
    "class BreastNetPP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BreastNetPP, self).__init__()\n",
    "        self.backbone = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.cbam = CBAM(1280)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(1280, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.extract_features(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        return self.sigmoid(self.fc2(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['benign', 'malignant']\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label, cls in enumerate(self.classes):\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            for img_name in os.listdir(cls_path):\n",
    "                self.image_paths.append(os.path.join(cls_path, img_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(160, 160),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(160, 160),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\"./Preprocessed/train\", transform=train_transform)\n",
    "val_dataset = CustomDataset(\"./Preprocessed/val\", transform=val_transform)\n",
    "test_dataset = CustomDataset(\"./Preprocessed/test\", transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BreastNetPP().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    loop = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    running_loss = 0\n",
    "    loop = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loop:\n",
    "            imgs, labels = imgs.to(device), labels.to(device).unsqueeze(1)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = (outputs > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "    accuracy = correct / total\n",
    "    return running_loss / len(loader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 1 | Train Loss: 0.2934 | Val Loss: 0.2460 | Val Acc: 0.8976\n",
      "\n",
      "üîÅ Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 2 | Train Loss: 0.2518 | Val Loss: 0.2343 | Val Acc: 0.9038\n",
      "\n",
      "üîÅ Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 8043/24977 [18:25<39:31,  7.14it/s, loss=0.205]  "
     ]
    }
   ],
   "source": [
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nüîÅ Epoch {epoch+1}/{num_epochs}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"‚úÖ Epoch {epoch+1} | Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc\n",
    "    }\n",
    "    torch.save(checkpoint, f\"{save_dir}/breastnetpp_epoch_{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af469e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_checkpoint_path = \"saved_models/breastnetpp_epoch_4.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23513830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Resumed training from epoch 4\n",
      "\n",
      "üîÅ Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|‚ñä         | 1943/24977 [04:56<58:51,  6.52it/s, loss=0.0747]  "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# resume_checkpoint_path = None  # set like \"saved_models/breastnetpp_epoch_6.pth\" if resuming\n",
    "start_epoch = 0\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Resume from checkpoint if provided\n",
    "if resume_checkpoint_path and os.path.exists(resume_checkpoint_path):\n",
    "    checkpoint = torch.load(resume_checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_val_acc = checkpoint.get('val_accuracy', 0.0)\n",
    "    print(f\"üîÑ Resumed training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"‚è≥ No checkpoint found or resume path not set. Starting fresh...\")\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"\\nüîÅ Epoch {epoch+1}/{num_epochs}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"‚úÖ Epoch {epoch+1} | Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save current epoch\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc\n",
    "    }\n",
    "    torch.save(checkpoint, f\"{save_dir}/breastnetpp_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), f\"{save_dir}/breastnetpp_best_model.pth\")\n",
    "        print(f\"üíæ Best model updated at epoch {epoch+1} with Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c0be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, test_loader, checkpoint_path):\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            outputs = model(imgs)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Flatten predictions and labels\n",
    "    y_pred = np.array(all_preds).flatten()\n",
    "    y_true = np.array(all_labels).flatten()\n",
    "\n",
    "    # Evaluation Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"üìä Evaluation Results:\")\n",
    "    print(f\"‚úÖ Accuracy  : {acc:.4f}\")\n",
    "    print(f\"‚úÖ Precision : {prec:.4f}\")\n",
    "    print(f\"‚úÖ Recall    : {rec:.4f}\")\n",
    "    print(f\"‚úÖ F1-Score  : {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"Benign\", \"Malignant\"]))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af9f706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183f0eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation Results:\n",
      "‚úÖ Accuracy  : 0.9072\n",
      "‚úÖ Precision : 0.8201\n",
      "‚úÖ Recall    : 0.8625\n",
      "‚úÖ F1-Score  : 0.8407\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.94      0.92      0.93     39748\n",
      "   Malignant       0.82      0.86      0.84     15758\n",
      "\n",
      "    accuracy                           0.91     55506\n",
      "   macro avg       0.88      0.89      0.89     55506\n",
      "weighted avg       0.91      0.91      0.91     55506\n",
      "\n",
      "Confusion Matrix:\n",
      "[[36766  2982]\n",
      " [ 2167 13591]]\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader, \"saved_models/breastnetpp_epoch_5.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633336b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuscenes_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
